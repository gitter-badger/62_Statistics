\documentclass[12pt]{article}
\usepackage{pmmeta}
\pmcanonicalname{ProofOfVarianceOfTheHypergeometricDistribution}
\pmcreated{2013-03-22 13:27:41}
\pmmodified{2013-03-22 13:27:41}
\pmowner{mathwizard}{128}
\pmmodifier{mathwizard}{128}
\pmtitle{proof of variance of the hypergeometric distribution}
\pmrecord{13}{34028}
\pmprivacy{1}
\pmauthor{mathwizard}{128}
\pmtype{Proof}
\pmcomment{trigger rebuild}
\pmclassification{msc}{62E15}

% this is the default PlanetMath preamble.  as your knowledge
% of TeX increases, you will probably want to edit this, but
% it should be fine as is for beginners.

% almost certainly you want these
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}

% used for TeXing text within eps files
%\usepackage{psfrag}
% need this for including graphics (\includegraphics)
%\usepackage{graphicx}
% for neatly defining theorems and propositions
%\usepackage{amsthm}
% making logically defined graphics
%%%\usepackage{xypic}

% there are many more packages, add them here as you need them

% define commands here
\begin{document}
We will first prove a useful property of binomial coefficients. We know
$${n\choose k}=\frac{n!}{k!(n-k)!}.$$
This can be transformed to
\begin{equation}\label{eq:binomial}
{n\choose k}=\frac{n}{k}\frac{(n-1)!}{(k-1)!(n-1-(k-1))!}=\frac{n}{k}{n-1\choose k-1}.
\end{equation}
The variance $\operatorname{Var}[X]$ of $X$ is given by:
$$\operatorname{Var}[X]=\sum_{x=0}^n\left(x-\frac{nK}{M}\right)^2\frac{{K\choose x}{M-K\choose n-x}}{{M\choose n}}.$$
We expand the right hand side:
\begin{eqnarray*}
\operatorname{Var}[X] & = & \sum_{x=0}^n\frac{x^2{K\choose x}{M-K\choose n-x}}{{M\choose n}}\\
&& -\frac{2nK}{M}\sum_{x=0}^n\frac{x{K\choose x}{M-K\choose n-x}}{{M\choose n}}\\
&& +\frac{n^2K^2}{M^2}\sum_{x=0}^n\frac{{K\choose x}{M-K\choose n-x}}{{M\choose n}}.
\end{eqnarray*}
The second of these sums is the expected value of the hypergeometric distribution, the third sum is $1$ as it sums up all probabilities in the distribution. So we have:
$$\operatorname{Var}[X]=-\frac{n^2K^2}{M^2}+\sum_{x=0}^n\frac{x^2{K\choose x}{M-K\choose n-x}}{{M\choose n}}.$$
In the last sum for $x=0$ we add nothing so we can write:
$$\operatorname{Var}[X]=-\frac{n^2K^2}{M^2}+\sum_{x=1}^n\frac{x^2{K\choose x}{M-K\choose n-x}}{{M\choose n}}.$$
Applying equation (\ref{eq:binomial}) and $x=(x-1)+1$ we get:
$$\operatorname{Var}[X]=-\frac{n^2K^2}{M^2}+\frac{nK}{M}\sum_{x=1}^n\frac{(x-1){K-1\choose x-1}{M-K\choose n-x}}{{M-1\choose n-1}}+\frac{nK}{M} \sum_{x=1}^n\frac{{K-1\choose x-1}{M-K\choose n-x}}{{M-1\choose n-1}}.$$
Setting $l:=x-1$ the first sum is the expected value of a hypergeometric distribution and is therefore given as $\frac{(n-1)(K-1)}{M-1}$. The second sum is the sum over all the probabilities of a hypergeometric distribution and is therefore equal to $1$. So we get:
\begin{eqnarray*}
\operatorname{Var}[X]&=&-\frac{n^2K^2}{M^2}+\frac{nK(n-1)(K-1)}{M(M-1)}+\frac{nK}{M}\\
&=&\frac{-n^2K^2(M-1)+Mn(n-1)K(K-1)+KnM(M-1)}{M^2(M-1)}\\
&=&\frac{nK(M^2+(-K-n)M+nK)}{M^2(M-1)}\\
&=&\frac{nK(M-K)(M-n)}{M^2(M-1)}\\
&=&n\frac{K}{M}\left(1-\frac{K}{M}\right)\frac{M-n}{M-1}.
\end{eqnarray*}
This \PMlinkescapetext{formula} is the one we wanted to prove.
%%%%%
%%%%%
\end{document}
